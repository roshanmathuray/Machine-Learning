# -*- coding: utf-8 -*-
"""GMM and BIRCH for Customer Identity and Brand Loyalty.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BYsryHdEIHNvFM7RodUHACvn8Zlkwv1u
"""

import streamlit as st
import pandas as pd

import streamlit as st
import pandas as pd

# Streamlit file uploader
uploaded_file = st.file_uploader("Choose a file", type=["csv", "txt"])

if uploaded_file is not None:
    # If a file is uploaded, read it
    df = pd.read_csv(uploaded_file)

    # Display the columns in the uploaded file
    st.write("Columns in the uploaded file:", df.columns)

    # Display the first few rows of the file
    st.write(df.head())

    # Assuming that the dataset has the required columns for clustering
    identity_loyalty_features = [
        "Income", "Recency", "MntWines", "MntFruits", "MntMeatProducts",
        "MntFishProducts", "MntSweetProducts", "MntGoldProds", "NumWebPurchases",
        "NumStorePurchases", "NumCatalogPurchases", "NumWebVisitsMonth", "NumDealsPurchases"
    ]

    # Check if all required columns are present in the uploaded dataset
    missing_columns = [col for col in identity_loyalty_features if col not in df.columns]
    if missing_columns:
        st.write(f"Warning: Missing columns in the uploaded file: {', '.join(missing_columns)}")
    else:
        # If all required columns are present, proceed with clustering
        df_identity_loyalty = df[identity_loyalty_features].copy()

        from sklearn.preprocessing import StandardScaler

        # Fill missing values with the median of each column
        df_identity_loyalty.fillna(df_identity_loyalty.median(), inplace=True)

        # Standardize the data for clustering
        scaler = StandardScaler()
        df_identity_loyalty_scaled = scaler.fit_transform(df_identity_loyalty)

        # Convert back to DataFrame
        df_identity_loyalty_scaled = pd.DataFrame(df_identity_loyalty_scaled, columns=df_identity_loyalty.columns)

        # Apply BIRCH clustering (3 clusters)
        from sklearn.cluster import Birch
        birch = Birch(n_clusters=3)
        df_identity_loyalty_scaled["BIRCH_Cluster"] = birch.fit_predict(df_identity_loyalty_scaled)

        # Apply GMM clustering (3 clusters)
        from sklearn.mixture import GaussianMixture
        gmm = GaussianMixture(n_components=3, random_state=42)
        df_identity_loyalty_scaled["GMM_Cluster"] = gmm.fit_predict(df_identity_loyalty_scaled)

        # Reduce to 2 dimensions for visualization
        from sklearn.decomposition import PCA
        import matplotlib.pyplot as plt
        import seaborn as sns

        pca = PCA(n_components=2)
        df_pca = pca.fit_transform(df_identity_loyalty_scaled.drop(columns=["BIRCH_Cluster", "GMM_Cluster"]))

        # Convert to DataFrame
        df_identity_loyalty_scaled["PCA_1"] = df_pca[:, 0]
        df_identity_loyalty_scaled["PCA_2"] = df_pca[:, 1]

        # Plot BIRCH clusters
        plt.figure(figsize=(12, 5))

        plt.subplot(1, 2, 1)
        sns.scatterplot(x="PCA_1", y="PCA_2",
                        hue="BIRCH_Cluster",
                        data=df_identity_loyalty_scaled,
                        palette="viridis")
        plt.title("BIRCH Clustering - Customer Identity & Brand Loyalty")
        plt.xlabel("PCA Feature 1")
        plt.ylabel("PCA Feature 2")

        # Plot GMM clusters
        plt.subplot(1, 2, 2)
        sns.scatterplot(x="PCA_1", y="PCA_2",
                        hue="GMM_Cluster",
                        data=df_identity_loyalty_scaled,
                        palette="coolwarm")
        plt.title("GMM Clustering - Customer Identity & Brand Loyalty")
        plt.xlabel("PCA Feature 1")
        plt.ylabel("PCA Feature 2")

        plt.tight_layout()
        plt.show()

        # Group data by BIRCH clusters and display the mean values
        st.write(df_identity_loyalty_scaled.groupby("BIRCH_Cluster").mean())
else:
    st.write("Please upload a CSV or TXT file to proceed.")